# TP3 - Questions (William Liaw)

<!-- arthur.lecair@telecom-paris.fr -->

## 1. DÃ©tection de contours

### 1.1. Filtre de gradient local par masque

<!-- https://medium.com/@haidarlina4/sobel-vs-canny-edge-detection-techniques-step-by-step-implementation-11ae6103a56a -->

- Rappelez l'intÃ©rÃªt du filtre de Sobel, par rapport au filtre diffÃ©rence, qui calcule une dÃ©rivÃ©e par la simple diffÃ©rence entre deux pixels voisins.
  - Le filtre Sobel met l'accent sur les pixels les plus proches du centre du masque, car pour obtenir le opÃ©rateur de Sobel, on effectue un produit externe entre un filtre gaussien 1D et la dÃ©rivÃ©e (difference). Le filtre gaussien est utilisÃ© pour rÃ©duire le bruit qui donne des images floues. Ainsi, l'opÃ©rateur Sobel calcule le gradient de l'image avec moins de bruit. L'opÃ©rateur Sobel est basÃ© sur la convolution de l'image avec un petit filtre sÃ©parable et Ã  valeurs entiÃ¨res dans les directions horizontale et verticale et est donc relativement peu coÃ»teux en termes de calculs. Il en va toutefois de mÃªme pour le filtre des diffÃ©rences, qui nÃ©cessite encore moins de puissance de calcul. Le filtre de diffÃ©rence simple ($2\times 2$), qui calcule la diffÃ©rence entre deux pixels voisins, est centrÃ© entre les pixels, ce qui provoque un dÃ©calage de l'image. En introduisant une colonne (ou une ligne) de zÃ©ros entre les coefficients asymÃ©triques, le filtre Sobel ($3\times 3$) est centrÃ© sur le pixel lui-mÃªme.
  - Filtre de Sobel

    ```
    [
      [1, 0, -1]
      [2, 0, -2]
      [1, 0, -1]
    ]
    ```

  - Filtre de differences

    ```
    [
      [1, 0]
      [-1, 0]
    ]
    ```

- Est-il nÃ©cessaire de faire un filtre passe-bas de l'image avant d'utiliser le filtre de Sobel?
  - L'intÃ©rÃªt d'utiliser un filtre passe-bas est de dÃ©bruiter l'image, amÃ©liorant ainsi la qualitÃ© des bords, ce qui, par extension, amÃ©liore la qualitÃ© de dÃ©tection des contours. Par consÃ©quent, la nÃ©cessitÃ© d'utiliser un filtre passe-bas avant d'appliquer le filtre Sobel dÃ©pend du niveau de bruit de l'image, pour des niveaux trÃ¨s faibles, la robustesse du filtre Sobel peut Ãªtre suffisante.
- Le seuillage de la norme du gradient permet d'obtenir des contours. Commentez la qualitÃ© des contours obtenus (robustesse au bruit, continuitÃ©, Ã©paisseur, position...) quand l'on fait varier ce seuil.
  - Lorsqu'on fixe un seuil trÃ¨s bas, les contours dÃ©tectÃ©s sont continus, cependant ils sont trÃ¨s sensibles au bruit et assez Ã©pais, ce qui implique une incertitude sur leur vÃ©ritable localisation, aussi on observe la dÃ©tection de faux contours. En augmentant le seuil, les contours deviennent plus fins (meilleure estimation de position) et plus robustes au bruit, au dÃ©triment de la continuitÃ©. De plus, bien que le nombre de faux contours dÃ©tectÃ©s soit rÃ©duit, une partie des vrais contours est Ã©galement perdue.

### 1.2. Maximum du gradient filtrÃ© dans la direction du gradient

- Quel critÃ¨re de qualitÃ© est optimisÃ© par ce procÃ©dÃ©?
  - Les critÃ¨res de Canny dÃ©finissent analytiquement les caractÃ©ristiques souhaitables pour la dÃ©tection de contours:
    - une bonne dÃ©tection, autant de bords que possible doivent Ãªtre dÃ©tectÃ©s avec prÃ©cision, ce qui signifie que le dÃ©tecteur doit avoir une rÃ©ponse forte mÃªme aux contours faibles et doit maximiser le rapport signal sur bruit;
    - bonne localisation, les points dÃ©tectÃ©s doivent Ãªtre au centre du contour;
    - rÃ©ponse unique, chaque contour ne doit Ãªtre dÃ©tectÃ© qu'une seule fois et le bruit ne doit pas crÃ©er de faux contours.
  - La procÃ©dure de dÃ©tection du maximum de gradient dans la direction du gradient n'est pas robuste au bruit et dÃ©tecte de nombreux faux bords, elle n'optimise donc pas les premier et troisiÃ¨me critÃ¨res. Cependant, en dÃ©tectant les maximums locaux du gradient, cette procÃ©dure trouve l'emplacement prÃ©cis des contours et donne des lignes fines, optimisant ainsi le deuxiÃ¨me critÃ¨re.
- Il est possible d'Ã©liminer les contours dont la norme est infÃ©rieur Ã  un seuil donnÃ©. Commentez les rÃ©sultats obtenus en terme de position et de continuitÃ© des contours, et de robustesse au bruit en faisant varier ce seuil.
  - Lorsqu'on applique la procÃ©dure de dÃ©tection du maximum du gradient sur la direction du gradient, on doit filtrer les contours dÃ©tectÃ©s par seuillage selon la norme du gradient, afin d'Ã©liminer les faux contours.
  - Plus le seuil est Ã©levÃ©, moins on dÃ©tecte de faux contours (plus robuste au bruit), cependant on perd la continuitÃ© et une partie des vrais contours. La localisation et l'Ã©paisseur des contours ne sont pas affectÃ©es.
- Cherchez Ã  fixer le seuil sur la norme de faÂ¸con Ã  obtenir un compromis entre robustesse au bruit et continuitÃ© des contours
  - En faisant varier le seuil utilisÃ© pour Ã©carter les contours en fonction de la norme du gradient, un bon compromis entre robustesse au bruit et continuitÃ© des contours semble Ãªtre trouvÃ© pour un seuil de 0,15: la plupart des contours parasites sont Ã©liminÃ©s, mÃªme si certaines microstructures subsistent et la majoritÃ© des cellules sont dÃ©tectÃ©es.

### 1.3. Filtre rÃ©cursif de Deriche

- Dans le fichier, **mrlab.py**, des erreurs ont Ã©tÃ© commises dans les fonctions **dericheGradX** et **dericheGradY**. A vous de corriger ces fonctions (uniquement au niveau des lignes indiquÃ©es) afin de mettre en Å“uvre la rÃ©cursivitÃ©.

  ```python
  def dericheGradX(ima, alpha):
      nl, nc = ima.shape
      ae = math.exp(-alpha)
      c = -(1 - ae) * (1 - ae) / ae

      b1 = np.zeros(nc)
      b2 = np.zeros(nc)

      gradx = np.zeros((nl, nc))

      for i in range(nl):
          l = ima[i,:].copy()

          for j in range(2, nc):
              b1[j] = l[j - 1] + 2 * ae * b1[j - 1] - ae * ae * b1[j - 2]
          b1[0] = b1[2]
          b1[1] = b1[2]

          for j in range(nc - 3, -1, -1):
              b2[j] = l[j + 1] + 2 * ae * b2[j + 1] - ae * ae * b2[j + 2]
          b2[nc - 2] = b2[nc - 3]
          b2[nc - 1] = b2[nc - 3]

          gradx[i,:] = c * ae * (b1 - b2)

      return gradx

  def dericheGradY(ima, alpha):
      nl, nc = ima.shape
      ae = math.exp(-alpha)
      c = -(1 - ae) * (1 - ae) / ae

      b1 = np.zeros(nl)
      b2 = np.zeros(nl)

      grady = np.zeros((nl, nc))

      for i in range(nc):
          l = ima[:, i].copy()

          for j in range(2, nl):
              b1[j] = l[j - 1] + 2 * ae * b1[j - 1] - ae * ae * b1[j - 2]
          b1[0] = b1[2]
          b1[1] = b1[2]

          for j in range(nl - 3, -1, -1):
              b2[j] = l[j + 1] + 2 * ae * b2[j + 1] - ae * ae * b2[j + 2]
          b2[nl - 1] = b2[nl - 3]
          b2[nl - 2] = b2[nl - 3]

          grady[:, i] = c * ae * (b1 - b2)

      return grady
  ```

- Testez la dÃ©tection de contours avec ce filtre sur plusieurs images. DÃ©crivez l'effet du paramÃ¨tre alpha sur les rÃ©sultats de la segmentation (faites varier ce paramÃ¨tre sur l'intervalle 0, 3...3, 0).
  - Le paramÃ¨tre d'Ã©chelle alpha du filtre de Deriche correspond Ã  l'inverse du paramÃ¨tre sigma du filtre de Canny, qui indique en dessous de quelle distance deux contours parallÃ¨les sont fusionnÃ©s. Par consÃ©quent, le paramÃ¨tre alpha peut Ãªtre ajustÃ© pour filtrer le bruit en reliant les arÃªtes adjacentes en contours longs, lisses et continus.
  - En rÃ©duisant le paramÃ¨tre alpha, nous observons une rÃ©duction du bruit et de la dÃ©tection parasite du contour. Cependant, en le rendant trop petit, les bords des diffÃ©rents objets commencent Ã  fusionner en un seul contour.
- Le temps de calcul dÃ©pend-il de la valeur de alpha? Expliquez pourquoi.
  - Le temps d'exÃ©cution du dÃ©tecteur de contours de Deriche ne dÃ©pend pas de la valeur de alpha, puisqu'il est uniquement utilisÃ© pour calculer les coefficients de l'expression rÃ©cursive, une fois les coefficients calculÃ©s, ses valeurs peuvent Ãªtre stockÃ©es. La valeur du paramÃ¨tre ne modifie pas le nombre d'opÃ©rations.
- Comment et dans quel but les fonctions **dericheSmoothX** et **dericheSmoothY** sont-elles utilisiÃ©es (cf. le filtre de Sobel)
  - Le filtre Deriche est initialement dÃ©fini en une dimension, il est ensuite Ã©tendu Ã  deux dimensions par l'application croisÃ©e de deux filtres, un dans la direction x (dÃ©tection de la composante verticale des arÃªtes), et un dans la direction y (dÃ©tection de la composante horizontale des bords). De plus, dans la direction du contour est dÃ©finie une fonction de lissage qui permet le filtrage du bruit, cette fonction correspond aux procÃ©dures dericheSmoothX et dericheSmoothY.
  - En conclusion, un filtre dÃ©tecteur de bord est composÃ© de deux estimateurs de dÃ©rivÃ©e, l'un dans la direction x et l'autre dans la direction y. Chacun de ces dÃ©tecteurs est composÃ© du produit de deux fonctions, en prenant par exemple le dÃ©tecteur dans la direction x, nous avons un filtre passe-bas selon Oy (fonction de lissage) et un filtre passe-haut selon Ox.

### 1.4. Passage par zÃ©ro du laplacien

- Quel est l'effet du paramÃ¨tre alpha sur les rÃ©sultats?
  - En rÃ©duisant le paramÃ¨tre alpha, nous observons une rÃ©duction du bruit et de la dÃ©tection parasite du contour. Cependant, en le rendant trop petit, les bords des diffÃ©rents objets commencent Ã  fusionner en un seul contour.
- Sur l'image **cell.tif**, quelles sont les principales diffÃ©rences par rapport aux rÃ©sultats fournis par les opÃ©rateurs vus prÃ©cÃ©demment (contours, Deriche)?
  - Les filtres Ã  gradient local, tels que le filtre Sobel, gÃ©nÃ¨rent uniquement des donnÃ©es de bord locales, au lieu de rÃ©cupÃ©rer la structure globale d'une frontiÃ¨re et sont trÃ¨s sensibles au bruit. La procÃ©dure de maximisation du gradient dans la direction du gradient ignore Ã©galement les structures globales, mais pas autant que les masques locaux, et est sensible au bruit, mais optimise au moins le critÃ¨re de localisation. D'un autre cÃ´tÃ©, le filtre de Deriche et les passages par zÃ©ro de la procÃ©dure laplacienne sont capables d'abstraire les structures globales, grÃ¢ce Ã  l'ajustement du paramÃ¨tre alpha, et le filtre de Deriche en particulier optimise tous les critÃ¨res de Canny. L'approche laplacienne prÃ©sente l'avantage de dÃ©tecter des contours fermÃ©s.
  - En comparant les rÃ©sultats obtenus sur l'image cell.tif pour la mÃ©thode laplacienne et le filtre de Deriche, nous observons que pour des valeurs plus Ã©levÃ©es de alpha le premier est moins robuste au bruit. Ceci s'explique par le fait que la mÃ©thode laplacienne ne prend pas en compte la norme du gradient.
- Sur l'image **pyramide.tif**, comment est-il possible de supprimer les faux contours crÃ©Ã©s par cette approche?
  - L'approche laplacienne prÃ©sente l'inconvÃ©nient que le laplacien des points d'inflexion d'une fonction est Ã©galement Ã©gal Ã  zÃ©ro, ce qui entraÃ®ne la dÃ©tection de faux contours sur des images en escalier, comme pyramide.tif. Pour Ã©liminer de tels contours, il est possible d'Ã©liminer les contours dont la norme est infÃ©rieure Ã  un seuil donnÃ© car comme ils ne correspondent pas aux bords rÃ©els, la norme du gradient sera trÃ¨s petite dans de telles rÃ©gions.

### 1.5. Changez d'image

- Quel opÃ©rateur choisiriez-vous pour segmenter l'image **pyra-gauss.tif**?
  - Puisque l'image **pyra-gauss.tif** est bruitÃ©e et en escalier, je choisirais l'opÃ©rateur de Deriche tel qu'il est le plus robuste au bruit et optimise les critÃ¨res de Canny, la dÃ©tection des faux contours dus au bruit peut Ã©galement Ãªtre contrÃ´lÃ©e grÃ¢ce Ã  l'ajustement du paramÃ¨tre alpha.
- Quels seraient les prÃ©-traitements et les post-traitements Ã  effectuer?
  - L'image **pyra-gauss.tif** Ã©tant bruitÃ©e, le prÃ©-traitement doit consister en une Ã©tape de dÃ©bruitage (convolution avec un filtre passe-bas). Et le post-traitement comprendrait la dÃ©tection du maximum du gradient dans la direction du gradient combinÃ©e Ã  une suppression de contour basÃ©e sur un seuillage de norme de gradient.

## 2. Seuillage avec hystÃ©rÃ©sis

### 2.1. Application Ã  la dÃ©tection de lignes

- Appliquez le filtre du Chapeau haut de forme (**tophat**) Ã  une image SPOT pour effectuer une dÃ©tection de lignes:
- Modifiez le rayon de l'Ã©lÃ©ment structurant utilisÃ© pour calculer le filtre **tophat**, et indiquez comment Ã©voluent les lignes dÃ©tectÃ©es.
  - En augmentant le rayon, les lignes dÃ©tectÃ©es deviennent plus Ã©paisses et plus continues, mais on constate Ã©galement une augmentation de la dÃ©tection des faux contours.
- Modifiez les valeurs des deux seuils, et examinez comment les lignes sont supprimÃ©es ou prÃ©servÃ©es. Quels sont les seuils qui donnent, Ã  votre avis, le meilleur rÃ©sultat?
  - Ã€ mon avis, pour un rayon de 5, les seuils haut et bas qui donnent les meilleurs rÃ©sultats pour **spot.tif** sont respectivement 2 et 15. Ce sont ces valeurs qui donnent le meilleur compromis entre la dÃ©tection des routes sur l'image et la rÃ©duction du nombre de contours parasites.
- Appliquez le seuillage par hystÃ©rÃ©sis pour amÃ©liorer la dÃ©tection de contours obtenue avec un des opÃ©rateurs vus prÃ©cÃ©demment sur une image de votre choix. PrÃ©cisez la mise en oeuvre que vous proposez et commentez les rÃ©sultats.
  - Un seuil d'hystÃ©rÃ©sis sera appliquÃ© pour amÃ©liorer la dÃ©tection de contour sur l'image **cell.tif** en utilisant l'opÃ©rateur Sobel combinÃ© avec le maximum du gradient dans la procÃ©dure de direction du gradient. Tout d'abord, comme Ã©tape de prÃ©-traitement, un filtre gaussien passe-bas est utilisÃ© pour dÃ©bruiter l'image. L'opÃ©rateur Sobel est ensuite appliquÃ© Ã  l'image pour calculer le gradient (norme et direction) et les contours sont dÃ©tectÃ©s comme le maximum du gradient dans la direction du gradient.
  - Ensuite, un seuillage par hystÃ©rÃ©sis est utilisÃ© pour amÃ©liorer la qualitÃ© de la dÃ©tection: un seuil est choisi suffisamment bas pour que les raies dÃ©tectÃ©es lors du seuillage de la norme de gradient soient continues, ce seuil est trÃ¨s sensible au bruit; un deuxiÃ¨me seuil est choisi suffisamment haut pour ne conserver que les points appartenant Ã  des contours valides. La deuxiÃ¨me image est ensuite utilisÃ©e pour sÃ©lectionner les contours de la premiÃ¨re image qui contiennent au moins un point conservÃ© par le seuil haut. L'image rÃ©sultante est utilisÃ©e comme masque appliquÃ© aux contours dÃ©tectÃ©s par le maximum du gradient dans la procÃ©dure de direction du gradient.
  - Le maximum du gradient dans la procÃ©dure dans le sens du gradient garantit une bonne localisation, tandis que le seuillage par hystÃ©rÃ©sis permet la suppression des contours parasites sans sacrifier la continuitÃ©.

## 3. Segmentation par classification: K-moyennes

### 3.1. Image Ã  niveau de gris

- Testez l'algorithme des k-moyennes sur l'image **cell.tif** pour une classification en 2 classes. Cette classification segmente-t-elle correctement les diffÃ©rents types de cellules? Si non, que proposez-vous?
  - L'algorithme des k-moyennes, pour k = 2, ne fait pas la diffÃ©rence entre les deux types de cellules diffÃ©rents, car l'une des classes est attribuÃ©e aux cellules et l'autre Ã  l'arriÃ¨re-plan. Autrement, pour classer diffÃ©rents types de cellules, nous pouvons augmenter le nombre de classes Ã  3.
- Testez les diffÃ©rentes possibilitÃ©s pour initialiser les classes. DÃ©crivez si possible ces diffÃ©rentes mÃ©thodes.
  - Dans l'implÃ©mentation du clustering k-means de Scikit Learn, les diffÃ©rentes possibilitÃ©s d'initialisation des classes sont:
    - sÃ©lectionner manuellement les centres initiaux et les transmettre comme arguments Ã  l'algorithme des k-moyennes;
    - choisir des observations au hasard parmi les donnÃ©es comme centroÃ¯des initiaux;
    - utiliser la technique Â« k-means++ Â» : un centre initial est choisi uniformÃ©ment au hasard parmi les points de donnÃ©es, le centre suivant est choisi parmi les points de donnÃ©es avec une probabilitÃ© proportionnelle Ã  la contribution du point au potentiel global, cette Ã©tape est rÃ©pÃ©tÃ©e jusqu'Ã  k Des centres ont Ã©tÃ© choisis.
- La classification obtenue est-elle stable (mÃªme position finale des centres des classes) avec une initialisation alÃ©atoire? Testez sur diffÃ©rentes images Ã  niveaux de gris et diffÃ©rents nombres de classes.
  - En exÃ©cutant plusieurs fois lâ€™algorithme k-means, avec une initialisation alÃ©atoire, nous observons que les centres de classes sont stables.
- Quelles sont les diï¬ƒcultÃ©s rencontrÃ©es pour la segmentation des diffÃ©rentes fibres musculaires dans l'image **muscle.tif**?
  - L'image **muscle.tif** a Ã©tÃ© segmentÃ©e en trois classes, dans le but de diffÃ©rencier le fond blanc, les fibres de couleur plus claire et celles de couleur plus foncÃ©e. En appliquant l'algorithme k-means, nous constatons qu'il ne parvient pas Ã  segmenter avec prÃ©cision les fibres de couleur plus claire, cela se produit parce qu'elles ont une texture granulaire, donc l'algorithme ne parvient pas Ã  les identifier comme un objet unique.
- Expliquez pourquoi le filtrage de lâ€™image originale (filtre de la moyenne ou filtre median) permet d'amÃ©liorer la classification.
  - Le filtrage de l'image avant la classification amÃ©liore les performances de l'algorithme k-means car les objets deviennent plus homogÃ¨nes; le bruit et la texture sont lissÃ©s.

### 3.2. Image en couleur

- Testez l'algorithme sur l'image **fleur.tif** pour une classification en 10 classes, les centres des classes initiaux Ã©tant tirÃ©s alÃ©atoirement.
- Commentez la dÃ©gradation de l'image quantifiÃ©e par rapport Ã  l'image initiale.
  - AprÃ¨s quantification, l'image est codÃ©e avec seulement 10 couleurs, donc, mÃªme si l'on peut encore distinguer les fleurs, certaines informations sont perdues par rapport Ã  l'image originale, cela est Ã©vident lÃ  oÃ¹ nous avions des dÃ©gradÃ©s de couleurs, qui se sont discrÃ©tisÃ©s. De plus, les couleurs les plus frÃ©quentes ont Ã©tÃ© conservÃ©es, tandis que les plus rares, comme le bleu, ont Ã©tÃ© perdues.
- Quel est le nombre minimum de classes qui donne un rendu visuel similaire Ã  celui de l'image codÃ©e sur 3 octets?
- En testant lâ€™algorithme pour un nombre croissant de classes, nous obtenons un rÃ©sultat visuellement similaire Ã  lâ€™image originale pour ð‘˜ = 9 classes.
- Proposez une solution pour retrouver les planches-mÃ¨res utilisÃ©es pour l'impression d'une carte IGN: **carte.tif**.
  - Pour retrouver les planches-mÃ¨res de la carte **carte.tif**, on pourrait d'abord appliquer un filtre moyen pour lisser les textures hachurÃ©es et pointillÃ©es, rendant homogÃ¨nes les zones appartenant Ã  une mÃªme classe. Ensuite, l'algorithme k-means pourrait Ãªtre utilisÃ© pour segmenter la carte en trois classes.

## 4. Seuillage automatique: Otsu

- Dans le script **otsu.py** quel critÃ¨re cherche-t-on Ã  optimiser?
  - Dans le script python, le critÃ¨re optimisÃ© est la minimisation de la variance intra-classe.
- Testez la mÃ©thode de Otsu sur diffÃ©rentes images Ã  niveaux de gris, et commentez les rÃ©sultats.
  - En appliquant la mÃ©thode de segmentation d'Otsu pour deux classes Ã  diffÃ©rentes images en niveaux de gris, nous constatons qu'elle ne parvient pas toujours Ã  distinguer les objets de l'arriÃ¨re-plan, cela est Ã©vident pour l'image reprÃ©sentant les fibres musculaires.
- Cette mÃ©thode permet-elle de seuiller correctement une image de norme du gradient?
  - La mÃ©thode dâ€™Otsu peut Ãªtre utilisÃ©e avec succÃ¨s pour dÃ©tecter les contours en choisissant un seuil adÃ©quat pour la norme du gradient.
- Modifiez ls script **otsu.py** pour traiter le problÃ¨me Ã  trois classes, i.e. la recherche de deux seuils

  ```python
  def otsu_thresh_modified(im):
      h = histogram(im)

      m = 0
      for i in range(256):
          m = m + i * h[i]

      mint1 = 0
      mint2 = 0
      minv = np.inf

      for t1 in range(1, 256 - 2):
          for t2 in range(t1 + 1, 256 - 1):
              w0 = 0
              w1 = 0
              w2 = 0
              m0 = 0
              m1 = 0
              m2 = 0
              v0 = 0
              v1 = 0
              v2 = 0

              for i in range(t1):
                  w0 = w0 + h[i]
                  m0 = m0 + i * h[i]
              if w0 > 0:
                  m0 = m0 / w0
              for i in range(t1):
                  v0 = v0 + h[i] * (i - m0) ** 2
              if w1 > 0:
                  v0 = v0 / w0

              for i in range(t1, t2):
                  w1 = w1 + h[i]
                  m1 = m1 + i * h[i]
              if w1 > 0:
                  m1 = m1 / w1
              for i in range(t1, t2):
                  v1 = v1 + h[i] * (i - m1) ** 2
              if w1 > 0:
                  v1 = v1 / w1

              for i in range(t2, 256):
                  w2 = w2 + h[i]
                  m2 = m2 + i * h[i]
              if w2 > 0:
                  m2 = m2 / w2
              for i in range(t2, 256):
                  v2 = v2 + h[i] * (i - m2) ** 2
              if w2 > 0:
                  v2 = v2 / w2

              v = w0 * v0 + w1 * v1 + w2 * v2

              if v < minv:
                  mint1 = t1
                  mint2 = t2
                  minv = v

      return (mint1, mint2)
  ```

## 5. Croissance de rÃ©gions

- Quelles contraintes doit vÃ©rifier un pixel pour Ãªtre ajoutÃ© Ã  l'objet existant?
  - Dans le script python **region_growing.py**, un pixel Ã  proximitÃ© d'un objet existant y est ajoutÃ© si la moyenne locale calculÃ©e sur le voisinage du pixel est comprise dans un seuil donnÃ© de la moyenne locale du germe d'origine.
- Les paramÃ¨tres Ã  fixer sont la position du point de dÃ©part *(x0, y0)*, un seuil *thresh* et le *rayon* qui dÃ©finit le voisinage sur lequel sont estimÃ©s la moyenne et l'Ã©cart-type locaux.
  - Plus le seuil est petit, plus le prÃ©dicat est strict, donc seuls des pixels trÃ¨s similaires au germe d'origine sont ajoutÃ©s Ã  l'objet, de cette faÃ§on, la rÃ©gion rÃ©sultante pourrait Ãªtre plus petite que l'objet rÃ©el et pourrait afficher des trous indÃ©sirables, car seules de lÃ©gÃ¨res dishomogÃ©nÃ©itÃ©s seront assez pour supprimer un pixel. En augmentant le seuil, le prÃ©dicat devient plus doux, permettant une plus grande croissance de la rÃ©gion. Si le seuil est trop grand, la rÃ©gion pourrait dÃ©passer les frontiÃ¨res du vÃ©ritable objet.
- Quel est l'effet du paramÃ¨tre *thresh* sur le rÃ©sultat de segmentation?
  - Le paramÃ¨tre **thres** correspond Ã  l'Ã©cart acceptable entre la couleur de la zone considÃ©rÃ©e et celle de la zone en expansion. Ainsi, plus **thres** est grand, plus l'objet final sera Ã©tendu, Ã©tant donnÃ© que l'on permet un plus grand Ã©cart de couleur.
- Quels paramÃ¨tres permettent de segmenter correctement la matiÃ¨re blanche?
  - Les paramÃ¨tres suivants permettent la segmentation correcte de la substance blanche :
    - (x0, y0) = (300, 300)
    - seuil = 4
    - rayon = 5
- Parvenez-vous Ã  segmenter la matiÃ¨re grise Ã©galement?
  - En choisissant le bon germe, nous pouvons Ã©galement segmenter la matiÃ¨re grise, mÃªme si seules les parties liÃ©es au germe d'origine sont dÃ©tectÃ©es. Les zones disjointes de matiÃ¨re grise, comme celles proches du centre du cerveau, ne sont pas dÃ©tectÃ©es.
- Quel est le prÃ©dicat mis en place dans ce script?
  - Le prÃ©dicat implÃ©mentÃ© est Â« la rÃ©gion est homogÃ¨ne Â», et lâ€™argument utilisÃ© est que la moyenne locale du voisinage de chaque pixel doit Ãªtre infÃ©rieure au temps sigma de la moyenne locale du voisinage du germe, oÃ¹ sigma est la norme dÃ©viation du voisinage du germe.
- Proposez un autre algorithme qui n'utilise pas la croissance de rÃ©gions, mais qui donne le mÃªme rÃ©sultat.
  - Ã‰tant donnÃ© le germe initial et les valeurs moyennes et standards de son voisinage, l'algorithme pourrait simplement vÃ©rifier pour chaque pixel de l'image si sa moyenne locale se situe dans le seuil souhaitÃ© de la moyenne locale du germe d'origine.
- Proposez un prÃ©dicat qui nÃ©cessite rÃ©ellement un algorithme de croissance de rÃ©gion.
  - Une adaptation du prÃ©dicat qui exigerait lâ€™utilisation de lâ€™algorithme de croissance de rÃ©gion serait Â« la rÃ©gion est homogÃ¨ne, connectÃ©e et contient le point initial Â».
